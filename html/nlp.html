<!DOCTYPE html>
<head>
    <meta charset = "utf-8">
    <title>About Libra</title>
    
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    
    <script src="../javascript/api.js" type="text/javascript"></script>
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,500,600" rel="stylesheet" type="text/css">
    <link href="../css/api.css" rel="stylesheet" type="text/css">
    <link href="../css/basic.css" rel=stylesheet type="text/css">
</head>
<body>
    <div id="side-nav">
        <img src = "../resources/libra-logo.png" id="icon">
        <ul class="nav">
            <li><a class="nav-tab" href="../index.html">About</a></li>
            
            <li><a class="nav-tab" href="started.html">Getting Started</a></li> 
            
            <li><a class="nav-tab" href="modeling.html">Modeling Queries</a></li>

            <li class="nav-tab selected" href="nlp.html">NLP Queries</li>
                <li class="dropdown-item selected" data="drp">Text Classification</li>
                <li class="dropdown-item" data="rff">Document Summarization</li>
                <li class="dropdown-item" data="pca">Principal Component Analysis</li>
                <li class="dropdown-item" data="ica">Independent Component Analysis</li>
            
            <li><a class="nav-tab" href="contributing.html">Contributing to Libra</a></li>                
        </ul>
    </div>
    <div id="nav-bar">Natural Language Processing Queries</div>
    <div id="content">
        <div class="box">
            <h1 id="drp">text_classification_query()</h1>
                <br>
                <p>Automatically fits a text classification model to your dataset. All standard text modification procedures are applied automatically if applicable..</p>
                <b>Only instruction is required. ALL other parameters are optional</b>
                <br>
                <br>
                <table>
                    <tr>
                        <td colspan="2">Arguments</td>
                    </tr>
                    <tr>
                        <td>Instruction=None</td>
                        <td>An English language statement that represents the task you would like to be completed. eg: 'predict the median house value' or 'please estimate the number of households'</td>
                    </tr>
                    <tr>
                        <td>preprocess=True</td>
                        <td>Whether you want your dataset to be intelligently preprocessed.</td>
                    </tr>
                    <tr>
                        <td>test_size=0.2</td>
                        <td>The proportion of your entire dataset that is used for testing. </td>
                    </tr>
                    <tr>
                        <td>random_state=49</td>
                        <td>The randomization channel that you want to be set at.</td>
                    </tr>
                    <tr>
                        <td>learning_rate=1e-2</td>
                        <td>The default rate at which your model learns based on gradient descent.</td>
                    </tr>
                    <tr>
                        <td>epochs=20</td>
                        <td>Number of epochs. This is for every model that's created in the process.</td>
                    </tr>
                    <tr>
                        <td>epochs=50</td>
                        <td>Number of epochs for every model attempted</td>
                    </tr>
                    <tr>
                        <td>monitor='val_loss'</td>
                        <td>The parameter that you want the query to minimize/maximize. For example, the default setting will try to minimize your validation loss.</td>
                    </tr>
                    <tr>
                        <td>generate_plots=True</td>
                        <td>Whether you want libra to create accuracy and loss plots for you. </td>
                    </tr>
                    <tr>
                        <td>batch_size=32</td>
                        <td>The number of dataset points that will be provided to your model in every pass.</td>
                    </tr>
                    <tr>
                        <td>max_text_length=200</td>
                        <td>The maximum amount of text that can be used to classify. If larger, it will cut off the rest.</td>
                    </tr>
                    <tr>
                        <td>max_features=20000</td>
                        <td>The size of the input embedding layer in the model.</td>
                    </tr>
                    <tr>
                        <td>generate_plots=True</td>
                        <td>Whether you want libra to create accuracy and loss plots for you.</td>
                    </tr>
                    <tr>
                        <td>save_model=False</td>
                        <td>Do you want the model weights and architecture to be saved as a .json and .h5 file.</td>
                    </tr>
                    <tr>
                        <td>save_path=os.getcwd()</td>
                        <td>Where do you want the save_model information to be stored. Default is current working directory.</td>
                    </tr>
                </table>
                <pre>new_client = client('path_to_dataset')
new_client.neural_network_query('Please estimate the number of households.')
new_client.models['regression_ANN'].plots() #access plots</pre>
        </div>
        <div class="box">
                <h1 id="rff">summarization_query()</h1>
                <br>
                <p>Automatically fits a Document Summarization transfer learning model to your dataset. This model will have frozen layers with pretrained weights to help with small dataset sizes.
                </p>
                <br>
                <table>
                    <tr>
                        <td colspan="2">Arguments</td>
                    </tr>
                    <tr>
                        <td>drop=None</td>
                        <td>Columns to drop manually, drop columns with links, weirdly formatted numbers, and others.</td>
                    </tr>
                    <tr>
                        <td>epochs=10</td>
                        <td>Number of epochs. This is for every model that's created in the process.</td>
                    </tr>
                    <tr>
                        <td>batch_size=32</td>
                        <td>The number of dataset points that will be provided to your model in every pass.</td>
                    </tr>
                    <tr>
                        <td>learning_rate=1e-2</td>
                        <td>The default rate at which your model learns based on gradient descent.</td>
                    </tr>
                    <tr>
                        <td>max_text_length=512</td>
                        <td>The maximum amount of text that can be summarized</td>
                    </tr>
                    <tr>
                        <td>max_summary_length=150</td>
                        <td>Maximum outputted summary length. The longer this is, the less accurate it will be.</td>
                    </tr>
                    <tr>
                        <td>gpu=false</td>
                        <td>Determines whether a built in cpu or gpu will be used.</td>
                    </tr>
                    <tr>
                        <td>generate_plots=True</td>
                        <td>Whether you want libra to create accuracy and loss plots for you.</td>
                    </tr>
                    <tr>
                        <td>save_model=False</td>
                        <td>Do you want the model weights and architecture to be saved as a .json and .h5 file.</td>
                    </tr>
                    <tr>
                        <td>save_path=os.getcwd()</td>
                        <td>Where do you want the save_model information to be stored. Default is current working directory.</td>
                    </tr>
                </table>
                <pre>newClient = client('path_to_directory_with_image_folders')
newClient.convolutional_query("Please classify my images")</pre>
        </div>
        <div class="box">
                <h1 id="pca">principal_component_analysis()</h1>
                <br>
                <p>Lets you create a text classification model automatically; works for all sorts of situations like sentiment analysis.</p>
                <br>
                <table>
                    <tr>
                        <td colspan="2">Arguments</td>
                    </tr>
                    <tr>
                        <td>Instruction</td>
                        <td>An English language statement that represents the task you would like to be completed. eg: 'predict the median house value' or 'please estimate the number of households'</td>
                    </tr>
                </table>
                <pre>newClient = client('path_to_file')
newClient.text_classification_query('Model credit card transaction type')
newClient.predict_text_sentiment('new_text_to_classify')</pre>

        </div>
        <div class="box">
                <h1 id="ica">independant_component_analysis()</h1>
                <br>
                <p>Automatically fits a clustering algorithm to your dataset. Target detection, preprocessing, and scoring are done by default.</p>
                <br>
                <table>
                    <tr>
                        <td colspan="2">Arguments</td>
                    </tr>
                    <tr>
                        <td>preprocess=True</td>
                        <td>Whether you want your dataset to be intelligently preprocessed</td>
                    </tr>
                    <tr>
                        <td>generate_plots=True</td>
                        <td>Whether you want libra to create accuracy and loss plots for you.</td>
                    </tr>
                    <tr>
                        <td>drop=[]</td>
                        <td>Columns to drop manually, drop columns with links, weirdly formatted numbers, and others.</td>
                    </tr>
                    <tr>
                        <td>base_clusters=2</td>
                        <td>Base number of clusters that will be tested. From this parameter provided, more and more clusters will be tested until an optimal number is found. </td>
                    </tr>

                </table>
                <pre>newClient = client('path_to_file')
newClient.kmeans_clustering_query(preprocess=True, generate_plots=True, drop=[])</pre>
        </div>
        <div id="space"></div>
    </div>
</body>