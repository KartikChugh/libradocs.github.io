<!DOCTYPE html>
<head>
    <meta charset = "utf-8">
    <title>About Libra</title>
    
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    
    <script src="/javascript/api.js" type="text/javascript"></script>
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,500,600" rel="stylesheet" type="text/css">
    <link href="/css/api.css" rel="stylesheet" type="text/css">
</head>
<body>
    <div id="side-nav">
        <img src = "../resources/libra-logo.png" id="icon">
        <ul class="nav">
            <li class="nav-tab selected" href="index.html">About</li>
            
            <li><a class="nav-tab" href="/html/started.html">Getting Started</a></li> 
            
            <li><a class="nav-tab" href="/html/devGuides.html">Developer Guides</a></li> 
            
            <li><a class="nav-tab" href="/html/modeling.html">Modeling Queries</a></li>    
            
            <li><a class="nav-tab" href="/html/nlp.html">NLP Queries</a></li>
        </ul>
    </div>
    <div id="nav-bar">About</div>
    <div id="content">
          <h1>Why choose Libra?</h1>
<p>The recent emergence of machine learning has given rise to hundreds of different frameworks, so why would you use Libra? Here's why libra outperforms all these other alternatives. </p>
<hr>
<h2>We priotize ease of use and ergonomics.</h2>
<ul>
<li> Libra is a machine learning API designed for non-technical users. This means that it assumes that you have no background in ML whatsoever. </li>
<li>Never preprocessed data before? Never worked with complex graphing libraries to analyze your models? Never understood what a dropout or a pooling layer does? Perfect. None of this knowledge is required to get your hands dirty in machine learning with Libra.</li>
<li>This makes it very easy to test the possibility of machine learning in your work enviroment. Don't go out and hire a machine learning engineer before you know it's possible to integrate the technology in your current system. Be confident first.</a>.</li>
<li>This ease of use does not come at the cost of reduced flexibility: all parameters that can be passed into sklearn and keras algorithms can also be passed to Libra. On top of this, we've already setup preprocessing pipelines for you to tune if you'd like!</li>
</ul>

<hr>
<h2>Libra has a large community and many resources available</h2>
<p>With a strong core team and mentorship opportunities, Libra offers many sockets to find success.</p>
<p>Join our slack group, where the founding developers are constantly asking questions about the library.</p>
<p>If you're an organization, fill out our form today and we'll hold either live or online instruction on how to use our tools.</p>
<hr>
<h2 id="keras-makes-it-easy-to-turn-models-into-products">Libra is the nexus of modern machine learning</h2>
<p>We've combined technologies from the most popular platforms to create a complete experience</p>
<ul>
<li>Keras's model building techniques for improved modularity</li>
<li>TensorFlow's core computational power</li>
<li>PyTorch's Acceleration for optimization and efficiency</li>
<li>Sklearn's one-line approach to building and training models</li>
<li>Keras Tuner's intelligent neural network tuning strategies</li>
</ul>
<hr>
<h2 id="keras-has-strong-multigpu-amp-distributed-training-support">Keras has strong multi-GPU &amp; distributed training support</h2>
<p>Keras is scalable. Using the <a href="https://www.tensorflow.org/tutorials/distribute/keras">TensorFlow <code>DistributionStrategy</code> API</a>, which is supported natively by Keras,
you easily can run your models on large GPU clusters (up to thousands of devices) or an entire TPU pod, representing over one exaFLOPs of computing power.</p>
<p>Keras also has native support for mixed-precision training on the latest NVIDIA GPUs as well as on TPUs, which can offer up to 2x speedup for training and inference.</p>
<p>For more information, see our <a href="/guides/distributed_training/">guide to multi-GPU &amp; distributed training</a>.</p>
<hr>
<h2 id="keras-is-at-the-nexus-of-a-large-ecosystem">Keras is at the nexus of a large ecosystem</h2>
<p>Like you, we know firsthand that building and training a model is only one slice of a machine learning workflow. Keras is built for the real world,
and in the real world, a successful model begins with data collection and ends with production deployment. </p>
<p>Keras is at the center of a wide ecosystem of tightly-connected projects that together cover every step of the machine learning workflow, in particular:</p>
<ul>
<li>Rapid model prototyping with <a href="https://autokeras.com/">AutoKeras</a></li>
<li>Scalable model training in on GCP via <a href="https://github.com/tensorflow/cloud">TF Cloud</a></li>
<li>Hyperparameter tuning with <a href="https://keras-team.github.io/keras-tuner/">Keras Tuner</a></li>
<li>Extra layers, losses, metrics, callbacks... via <a href="https://www.tensorflow.org/addons/api_docs/python/tfa">TensorFlow Addons</a></li>
<li>Inference model quantization &amp; pruning with the <a href="https://www.tensorflow.org/model_optimization">TF Model Optimization Toolkit</a></li>
<li>Model deployment on mobile or on an embedded with <a href="https://www.tensorflow.org/lite">TF Lite</a></li>
<li>Model deployment in the browser via <a href="https://www.tensorflow.org/js">TF.js</a></li>
<li>...and many more.</li>
</ul>
        </div>
</body>